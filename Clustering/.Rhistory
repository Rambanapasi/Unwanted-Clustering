#
# get symbols from YF
getSymbols(stks, from=Sys.Date()-years(2), env = e)
closing_prices <- do.call(merge, eapply(e, Ad))
colnames(closing_prices) <- gsub(".Adjusted","",names(closing_prices))
# calc simple returns, monthly
data <- closing_prices %>%
tbl2xts::xts_tbl() %>%
arrange(date) %>%
gather(ticks, px, -date) %>%
mutate(stk = str_remove(ticks, ".JO")) %>%
select(date, stk, px)%>%
mutate(YM = format(date, "%y %b")) %>%
group_by(stk, YM) %>%
filter(date == max(date)) %>% ungroup() %>%
select(-YM)
df_rets <-  data %>%
group_by(stk) %>%
mutate(rets = px / lag(px) - 1) %>%
select(-px) %>%
ungroup() %>%
left_join(qualititive_factors, by = "stk")
# Step 1: Calculate sector returns as a simple average
sector_returns_simple <- df_rets %>%
group_by(date, industry) %>%  # Group by date and sector
summarize(
sector_ret = mean(rets, na.rm = TRUE),  # Average returns for the sector
.groups = "drop"
) %>% arrange(desc(date))
# Step 2: Calculate sector returns weighted by market cap
sector_returns_weighted <- df_rets %>%
group_by(date, industry) %>%  # Group by date and sector
summarize(
sector_ret = sum(rets * mkt.cap, na.rm = TRUE) / sum(mkt.cap, na.rm = TRUE),  # Weighted average
.groups = "drop"
) %>% arrange(desc(date))
# View the results
sector_returns_simple
sector_returns_weighted
rolling_sector_performance <- sector_returns_weighted %>%
arrange(industry, date) %>%  # Sort by industry and date
group_by(industry) %>%  # Group by sector
mutate(
rolling_3_month_perf = rollapply(
sector_ret,                  # The sector return column
width = 3,                   # Rolling window of 3 observations
FUN = mean,                  # Calculate the average over the window
align = "right",             # Align the window to the right
fill = NA                    # Fill missing values with NA for the first few rows
)
) %>%
ungroup()
ggplot(rolling_sector_performance, aes(x = date, y = rolling_3_month_perf, color = industry, group = industry)) +
geom_line(size = 1) +
labs(
title = "Rolling 3-Month Sector Performance (Market Cap Weighted)",
x = "Date",
y = "Rolling Performance",
color = "Industry"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12),
legend.title = element_text(size = 10),
legend.text = element_text(size = 9)
)
# clean and load from yahoo finance
data <- df %>%
mutate(stk = str_remove(stk, " SJ Equity")) %>%
arrange(desc(mkt.cap)) %>% head(40)
# to retrieve prices and volumes from yahoo finance
stks <- data %>%
select(stk) %>%
# filter(industry %in% c("Materials")) %>%
mutate(stk = paste0(stk, ".JO")) %>% select(stk) %>%
pull()
# fetch
e <- new.env()
#
# get symbols from YF
getSymbols(stks, from=Sys.Date()-years(2), env = e)
closing_prices <- do.call(merge, eapply(e, Ad))
colnames(closing_prices) <- gsub(".Adjusted","",names(closing_prices))
# calc simple returns, monthly
data <- closing_prices %>%
tbl2xts::xts_tbl() %>%
arrange(date) %>%
gather(ticks, px, -date) %>%
mutate(stk = str_remove(ticks, ".JO")) %>%
select(date, stk, px)%>%
mutate(YM = format(date, "%y %b")) %>%
group_by(stk, YM) %>%
filter(date == max(date)) %>% ungroup() %>%
select(-YM)
df_rets <-  data %>%
group_by(stk) %>%
mutate(rets = px / lag(px) - 1) %>%
select(-px) %>%
ungroup() %>%
left_join(qualititive_factors, by = "stk")
# Step 1: Calculate sector returns as a simple average
sector_returns_simple <- df_rets %>%
group_by(date, industry) %>%  # Group by date and sector
summarize(
sector_ret = mean(rets, na.rm = TRUE),  # Average returns for the sector
.groups = "drop"
) %>% arrange(desc(date))
# Step 2: Calculate sector returns weighted by market cap
sector_returns_weighted <- df_rets %>%
group_by(date, industry) %>%  # Group by date and sector
summarize(
sector_ret = sum(rets * mkt.cap, na.rm = TRUE) / sum(mkt.cap, na.rm = TRUE),  # Weighted average
.groups = "drop"
) %>% arrange(desc(date))
# View the results
sector_returns_simple
sector_returns_weighted
rolling_sector_performance <- sector_returns_weighted %>%
arrange(industry, date) %>%  # Sort by industry and date
group_by(industry) %>%  # Group by sector
mutate(
rolling_3_month_perf = rollapply(
sector_ret,                  # The sector return column
width = 3,                   # Rolling window of 3 observations
FUN = mean,                  # Calculate the average over the window
align = "right",             # Align the window to the right
fill = NA                    # Fill missing values with NA for the first few rows
)
) %>%
ungroup()
ggplot(rolling_sector_performance, aes(x = date, y = rolling_3_month_perf, color = industry, group = industry)) +
geom_line(size = 1) +
labs(
title = "Rolling 3-Month Sector Performance (Market Cap Weighted)",
x = "Date",
y = "Rolling Performance",
color = "Industry"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12),
legend.title = element_text(size = 10),
legend.text = element_text(size = 9)
)
# Filter for data starting 6 months ago and calculate cumulative returns
cumulative_sector_returns <- sector_returns_weighted %>%
filter(date >= Sys.Date() - months(6)) %>%  # Filter for dates in the last 6 months
group_by(industry) %>%  # Group by sector
arrange(date) %>%  # Ensure data is ordered by date
mutate(
cumulative_ret = cumprod(1 + sector_ret) - 1  # Calculate cumulative returns
) %>%
ungroup()
# Plot cumulative returns
ggplot(cumulative_sector_returns, aes(x = date, y = cumulative_ret, color = industry, group = industry)) +
geom_line(size = 1) +  # Line plot for cumulative returns
labs(
title = "Cumulative Sector Returns (Last 6 Months)",
x = "Date",
y = "Cumulative Return",
color = "Industry"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12),
legend.title = element_text(size = 10),
legend.text = element_text(size = 9)
)
# Filter data for the last 6 months and compute statistics
sector_stats_last_6_months <- df_rets %>%
filter(date >= Sys.Date() - months(6)) %>%  # Filter for the last 6 months
group_by(stk, industry) %>%  # Group by stock and sector
summarize(
cumulative_return = prod(1 + rets, na.rm = TRUE)-1,  # Cumulative return
average_return = mean(rets, na.rm = TRUE),  # Average return
volatility = sd(rets, na.rm = TRUE),  # Volatility (standard deviation)
.groups = "drop"
) %>%
group_by(industry) %>%  # Group by sector
slice_max(cumulative_return, n = 2, with_ties = FALSE) %>%  # Select top stock by cumulative return
ungroup()
# View the results
sector_stats_last_6_months
getSymbols("^J203.JO", src = "yahoo", from=Sys.Date()-years(10))
bm <- J203.JO%>%
tbl2xts::xts_tbl() %>% select(date, J203.JO.Close ) %>%
rename(px = J203.JO.Close) %>%
mutate(YM = format(date, "%y %b")) %>%
group_by(YM) %>%
filter(date == max(date)) %>% ungroup() %>%
select(-YM)
# create relative strength and list within sectors. we caculate based on the the returns of the benchmark being the JSE top 40
rs <-  data %>% spread(., stk, px)
bm <- bm %>% rename("BM"= px)
# get the relative strength
calc <- rs %>%
merge(., bm, by = "date") %>%
mutate(across(-date, ~ . /BM)) %>%
select(-BM) %>%
gather(share, RS, -date)
# lets arrange, get the top and bottom decile performers
top_bottom_deciles <- calc %>% arrange(desc(RS)) %>%
group_by(date) %>%
mutate(
decile = ntile(RS, 10)
) %>%
filter(decile == 10) %>% group_by(share) %>% filter(date == max(date)) %>%
arrange(desc(decile))
labelling <- top_bottom_deciles %>% select(share) %>%
distinct() %>%
pull()
#
Top_RSI <- df_rets %>%
# filter(stk %in% for_clustering) %>%
spread(stk, rets) %>% slice(-1)
# for safety in our return
impute_missing_returns <- function(return_mat, impute_returns_method = "NONE", Seed = 1234){
# Make sure we have a date column called date:
if( !"date" %in% colnames(return_mat) ) stop("No 'date' column provided in return_mat. Try again please.")
# Note my use of 'any' below...
# Also note that I 'return' return_mat - which stops the function and returns return_mat.
if( impute_returns_method %in% c("NONE", "None", "none") ) {
if( any(is.na(return_mat)) ) warning("There are missing values in the return matrix.. Consider maybe using impute_returns_method = 'Drawn_Distribution_Own' / 'Drawn_Distribution_Collective'")
return(return_mat)
}
if( impute_returns_method  == "Average") {
return_mat <-
return_mat %>% gather(Stocks, Returns, -date) %>%
group_by(date) %>%
mutate(Avg = mean(Returns, na.rm=T)) %>%
mutate(Avg = coalesce(Avg, 0)) %>% # date with no returns - set avg to zero
ungroup() %>%
mutate(Returns = coalesce(Returns, Avg)) %>% select(-Avg) %>% spread(Stocks, Returns)
# That is just so much easier when tidy right? See how I gathered and spread again to give back a wide df?
return(return_mat)
} else
if( impute_returns_method  == "Drawn_Distribution_Own") {
set.seed(Seed)
N <- nrow(return_mat)
return_mat <-
# DIY: see what density function does
left_join(return_mat %>% gather(Stocks, Returns, -date),
return_mat %>% gather(Stocks, Returns, -date) %>% group_by(Stocks) %>%
mutate(Dens = list(density(Returns, na.rm=T))) %>%
summarise(Random_Draws = list(sample(Dens[[1]]$x, N, replace = TRUE, prob=.$Dens[[1]]$y))),
by = "Stocks"
) %>%  group_by(Stocks) %>%
# Random draw from sample:
mutate(Returns = coalesce(Returns, Random_Draws[[1]][row_number()])) %>%
select(-Random_Draws) %>% ungroup() %>% spread(Stocks, Returns)
return(return_mat)
} else
if( impute_returns_method  == "Drawn_Distribution_Collective") {
set.seed(Seed)
NAll <- nrow(return_mat %>% gather(Stocks, Returns, -date))
# DIY: see what density function does
return_mat <-
bind_cols(
return_mat %>% gather(Stocks, Returns, -date),
return_mat %>% gather(Stocks, Returns, -date) %>%
mutate(Dens = list(density(Returns, na.rm=T))) %>%
summarise(Random_Draws = list(sample(Dens[[1]]$x, NAll, replace = TRUE, prob=.$Dens[[1]]$y))) %>%
unnest(Random_Draws)
) %>%
mutate(Returns = coalesce(Returns, Random_Draws)) %>% select(-Random_Draws) %>% spread(Stocks, Returns)
return(return_mat)
} else
if( impute_returns_method  == "Zero") {
warning("This is probably not the best idea but who am I to judge....")
return_mat[is.na(return_mat)] <- 0
return(return_mat)
} else
stop("Please provide a valid impute_returns_method method. Options include:\n'Average', 'Drawn_Distribution_Own', 'Drawn_Distribution_Collective' and 'Zero'.")
return_mat
}
# Now we will use this function as follows (after saving and sourcing it of course....):
# Note my seed is the year, day hour and minute - so unless you do this multiple times a minute, it will always differ.
options(scipen = 999)
return_mat <- impute_missing_returns(Top_RSI, impute_returns_method = "Drawn_Distribution_Collective", Seed = as.numeric(format( Sys.time(), "%Y%d%H%M"))) %>% select(-date)
rm(list = ls())
gc()
library(tidyverse)
library(tidyquant)
library(fmxdat)
library(ggdendro)
list.files('code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))
# load data
df <- readxl::read_xlsx("data/JALSH as of Apr 10 20241_vsoj2gma.xlsx")
# get the labels for the sectors
qualititive_factors <-  df %>%select(stk, industry, mkt.cap ) %>%
mutate(stk = str_remove(stk, " SJ Equity"))
# clean and load from yahoo finance
data <- df %>%
mutate(stk = str_remove(stk, " SJ Equity")) %>%
arrange(desc(mkt.cap)) %>% head(40)
# to retrieve prices and volumes from yahoo finance
stks <- data %>%
select(stk) %>%
# filter(industry %in% c("Materials")) %>%
mutate(stk = paste0(stk, ".JO")) %>% select(stk) %>%
pull()
# fetch
e <- new.env()
#
# get symbols from YF
getSymbols(stks, from=Sys.Date()-years(2), env = e)
closing_prices <- do.call(merge, eapply(e, Ad))
colnames(closing_prices) <- gsub(".Adjusted","",names(closing_prices))
# calc simple returns, monthly
data <- closing_prices %>%
tbl2xts::xts_tbl() %>%
arrange(date) %>%
gather(ticks, px, -date) %>%
mutate(stk = str_remove(ticks, ".JO")) %>%
select(date, stk, px)%>%
mutate(YM = format(date, "%y %b")) %>%
group_by(stk, YM) %>%
filter(date == max(date)) %>% ungroup() %>%
select(-YM)
df_rets <-  data %>%
group_by(stk) %>%
mutate(rets = px / lag(px) - 1) %>%
select(-px) %>%
ungroup() %>%
left_join(qualititive_factors, by = "stk")
# Step 1: Calculate sector returns as a simple average
sector_returns_simple <- df_rets %>%
group_by(date, industry) %>%  # Group by date and sector
summarize(
sector_ret = mean(rets, na.rm = TRUE),  # Average returns for the sector
.groups = "drop"
) %>% arrange(desc(date))
# Step 2: Calculate sector returns weighted by market cap
sector_returns_weighted <- df_rets %>%
group_by(date, industry) %>%  # Group by date and sector
summarize(
sector_ret = sum(rets * mkt.cap, na.rm = TRUE) / sum(mkt.cap, na.rm = TRUE),  # Weighted average
.groups = "drop"
) %>% arrange(desc(date))
# View the results
sector_returns_simple
sector_returns_weighted
rolling_sector_performance <- sector_returns_weighted %>%
arrange(industry, date) %>%  # Sort by industry and date
group_by(industry) %>%  # Group by sector
mutate(
rolling_3_month_perf = rollapply(
sector_ret,                  # The sector return column
width = 3,                   # Rolling window of 3 observations
FUN = mean,                  # Calculate the average over the window
align = "right",             # Align the window to the right
fill = NA                    # Fill missing values with NA for the first few rows
)
) %>%
ungroup()
ggplot(rolling_sector_performance, aes(x = date, y = rolling_3_month_perf, color = industry, group = industry)) +
geom_line(size = 1) +
labs(
title = "Rolling 3-Month Sector Performance (Market Cap Weighted)",
x = "Date",
y = "Rolling Performance",
color = "Industry"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12),
legend.title = element_text(size = 10),
legend.text = element_text(size = 9)
)
# Filter for data starting 6 months ago and calculate cumulative returns
cumulative_sector_returns <- sector_returns_weighted %>%
filter(date >= Sys.Date() - months(6)) %>%  # Filter for dates in the last 6 months
group_by(industry) %>%  # Group by sector
arrange(date) %>%  # Ensure data is ordered by date
mutate(
cumulative_ret = cumprod(1 + sector_ret) - 1  # Calculate cumulative returns
) %>%
ungroup()
# Plot cumulative returns
ggplot(cumulative_sector_returns, aes(x = date, y = cumulative_ret, color = industry, group = industry)) +
geom_line(size = 1) +  # Line plot for cumulative returns
labs(
title = "Cumulative Sector Returns (Last 6 Months)",
x = "Date",
y = "Cumulative Return",
color = "Industry"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
axis.title = element_text(size = 12),
legend.title = element_text(size = 10),
legend.text = element_text(size = 9)
)
# Filter data for the last 6 months and compute statistics
sector_stats_last_6_months <- df_rets %>%
filter(date >= Sys.Date() - months(6)) %>%  # Filter for the last 6 months
group_by(stk, industry) %>%  # Group by stock and sector
summarize(
cumulative_return = prod(1 + rets, na.rm = TRUE)-1,  # Cumulative return
average_return = mean(rets, na.rm = TRUE),  # Average return
volatility = sd(rets, na.rm = TRUE),  # Volatility (standard deviation)
.groups = "drop"
) %>%
group_by(industry) %>%  # Group by sector
slice_max(cumulative_return, n = 2, with_ties = FALSE) %>%  # Select top stock by cumulative return
ungroup()
# View the results
sector_stats_last_6_months
getSymbols("^J203.JO", src = "yahoo", from=Sys.Date()-years(10))
bm <- J203.JO%>%
tbl2xts::xts_tbl() %>% select(date, J203.JO.Close ) %>%
rename(px = J203.JO.Close) %>%
mutate(YM = format(date, "%y %b")) %>%
group_by(YM) %>%
filter(date == max(date)) %>% ungroup() %>%
select(-YM)
# create relative strength and list within sectors. we caculate based on the the returns of the benchmark being the JSE top 40
rs <-  data %>% spread(., stk, px)
bm <- bm %>% rename("BM"= px)
# get the relative strength
calc <- rs %>%
merge(., bm, by = "date") %>%
mutate(across(-date, ~ . /BM)) %>%
select(-BM) %>%
gather(share, RS, -date)
# lets arrange, get the top and bottom decile performers
top_bottom_deciles <- calc %>% arrange(desc(RS)) %>%
group_by(date) %>%
mutate(
decile = ntile(RS, 10)
) %>%
filter(decile == 10) %>% group_by(share) %>% filter(date == max(date)) %>%
arrange(desc(decile))
labelling <- top_bottom_deciles %>% select(share) %>%
distinct() %>%
pull()
#
Top_RSI <- df_rets %>%
# filter(stk %in% for_clustering) %>%
spread(stk, rets) %>% slice(-1)
# for safety in our return
impute_missing_returns <- function(return_mat, impute_returns_method = "NONE", Seed = 1234){
# Make sure we have a date column called date:
if( !"date" %in% colnames(return_mat) ) stop("No 'date' column provided in return_mat. Try again please.")
# Note my use of 'any' below...
# Also note that I 'return' return_mat - which stops the function and returns return_mat.
if( impute_returns_method %in% c("NONE", "None", "none") ) {
if( any(is.na(return_mat)) ) warning("There are missing values in the return matrix.. Consider maybe using impute_returns_method = 'Drawn_Distribution_Own' / 'Drawn_Distribution_Collective'")
return(return_mat)
}
if( impute_returns_method  == "Average") {
return_mat <-
return_mat %>% gather(Stocks, Returns, -date) %>%
group_by(date) %>%
mutate(Avg = mean(Returns, na.rm=T)) %>%
mutate(Avg = coalesce(Avg, 0)) %>% # date with no returns - set avg to zero
ungroup() %>%
mutate(Returns = coalesce(Returns, Avg)) %>% select(-Avg) %>% spread(Stocks, Returns)
# That is just so much easier when tidy right? See how I gathered and spread again to give back a wide df?
return(return_mat)
} else
if( impute_returns_method  == "Drawn_Distribution_Own") {
set.seed(Seed)
N <- nrow(return_mat)
return_mat <-
# DIY: see what density function does
left_join(return_mat %>% gather(Stocks, Returns, -date),
return_mat %>% gather(Stocks, Returns, -date) %>% group_by(Stocks) %>%
mutate(Dens = list(density(Returns, na.rm=T))) %>%
summarise(Random_Draws = list(sample(Dens[[1]]$x, N, replace = TRUE, prob=.$Dens[[1]]$y))),
by = "Stocks"
) %>%  group_by(Stocks) %>%
# Random draw from sample:
mutate(Returns = coalesce(Returns, Random_Draws[[1]][row_number()])) %>%
select(-Random_Draws) %>% ungroup() %>% spread(Stocks, Returns)
return(return_mat)
} else
if( impute_returns_method  == "Drawn_Distribution_Collective") {
set.seed(Seed)
NAll <- nrow(return_mat %>% gather(Stocks, Returns, -date))
# DIY: see what density function does
return_mat <-
bind_cols(
return_mat %>% gather(Stocks, Returns, -date),
return_mat %>% gather(Stocks, Returns, -date) %>%
mutate(Dens = list(density(Returns, na.rm=T))) %>%
summarise(Random_Draws = list(sample(Dens[[1]]$x, NAll, replace = TRUE, prob=.$Dens[[1]]$y))) %>%
unnest(Random_Draws)
) %>%
mutate(Returns = coalesce(Returns, Random_Draws)) %>% select(-Random_Draws) %>% spread(Stocks, Returns)
return(return_mat)
} else
if( impute_returns_method  == "Zero") {
warning("This is probably not the best idea but who am I to judge....")
return_mat[is.na(return_mat)] <- 0
return(return_mat)
} else
stop("Please provide a valid impute_returns_method method. Options include:\n'Average', 'Drawn_Distribution_Own', 'Drawn_Distribution_Collective' and 'Zero'.")
return_mat
}
# Now we will use this function as follows (after saving and sourcing it of course....):
# Note my seed is the year, day hour and minute - so unless you do this multiple times a minute, it will always differ.
options(scipen = 999)
return_mat <- impute_missing_returns(Top_RSI, impute_returns_method = "Drawn_Distribution_Collective", Seed = as.numeric(format( Sys.time(), "%Y%d%H%M"))) %>% select(-date)
devtools::source_gist("https://gist.github.com/Nicktz/bd2614f8f8a551881a1dc3c11a1e7268")
cluster_aux()
hcdata <- dendro_data_k(cluster, 4)
